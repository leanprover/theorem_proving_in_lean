#+Title: Theorem Proving in Lean
#+Author: [[http://www.andrew.cmu.edu/user/avigad][Jeremy Avigad]], [[http://leodemoura.github.io][Leonardo de Moura]], [[http://www.cs.cmu.edu/~soonhok][Soonho Kong]]

* Tactics
:PROPERTIES:
  :CUSTOM_ID: Tactics
:END:

In this chapter, we describe an alternative approach to constructing
proofs, using /tactics/. A proof term is a representation of a
mathematical proof; tactics are commands, or instructions, that
describe how to build such a proof. Informally, we might begin a
mathematical proof by saying "to prove the forward direction, unfold
the definition, apply the previous lemma, and simplify." Just as these
are instructions that tell the reader how to find the relevant proof,
tactics are instructions that tell Lean how to construct a proof term.
They naturally support an incremental style of writing proofs, in
which users decompose a proof and work on goals one step at a time.

We will describe proofs that consist of sequences of tactics as
"tactic-style" proofs, to contrast with the ways of writing proof
terms we have seen so far, which we will call "term-style"
proofs. Each style has its own advantages and disadvantages. For
example, tactic-style proofs can be harder to read, because they
require the reader to predict or guess the results of each
instruction. But they can also be shorter and easier to
write. Moreover, tactics offer a gateway to using Lean's automation,
since automated procedures are themselves tactics.

** Entering Tactic Mode

Conceptually, stating a theorem or introducing a =have= statement
creates a goal, namely, the goal of constructing a term with the
expected type. For example, the following creates the goal of
constructing a term of type =p ∧ q ∧ p=, in a context with constants
=p q : Prop=, =hp : p= and =hq : q=:
#+BEGIN_SRC lean
theorem test (p q : Prop) (hp : p) (hq : q) : p ∧ q ∧ p :=
sorry
#+END_SRC
We can write this goal as follows:
#+BEGIN_SRC text
p : Prop, q : Prop, hp : p, hq : q ⊢ p ∧ q ∧ p
#+END_SRC
Indeed, if you replace the "sorry" by an underscore in the example
above, Lean will report that it is exactly this goal that has been
left unsolved.

Ordinarily, we meet such a goal by writing an explicit term. But
wherever a term is expected, Lean allows us to insert instead a =begin
... end= block, followed by a sequence of commands, separated by
commas. We can prove the theorem above in that way:
#+BEGIN_SRC lean
theorem test (p q : Prop) (hp : p) (hq : q) : p ∧ q ∧ p :=
begin
  apply and.intro,
  exact hp,
  apply and.intro,
  exact hq,
  exact hp
end
#+END_SRC
The =apply= tactic applies an expression, viewed as denoting a
function with zero or more arguments. It unifies the conclusion with
the expression in the current goal, and creates new goals for the
remaining arguments, provided that no later arguments depend on
them. In the example above, the command =apply and.intro= yields two
subgoals:
#+BEGIN_SRC text
p : Prop,
q : Prop,
hp : p,
hq : q
⊢ p

⊢ q ∧ p
#+END_SRC
For brevity, Lean only displays the context for the first goal, which
is the one addressed by the next tactic command. The first goal is met
with the command =exact hp=. The =exact= command is just a variant of
=apply= which signals that the expression given should fill the goal
exactly. It is good form to use it in a tactic proof, since its
failure signals that something has gone wrong; but otherwise =apply=
would work just as well.

You can see the resulting proof term with the =print= command:
#+BEGIN_SRC lean
theorem test (p q : Prop) (hp : p) (hq : q) : p ∧ q ∧ p :=
begin
  apply and.intro,
  exact hp,
  apply and.intro,
  exact hq,
  exact hp
end

-- BEGIN
print test
-- END
#+END_SRC

You can write a tactic script incrementally. If you run Lean on an
incomplete tactic proof bracketed by =begin= and =end=, the system
reports all the unsolved goals that remain. If you are running Lean
with its Emacs interface, you can see this information by putting your
cursor on the =end= symbol, which should be underlined. In the Emacs
interface, there is another extremely useful trick: if you put your
cursor on a line of a tactic proof and press "C-c C-g", Lean will show
you the goal that remains at the end of the line.

Tactic commands can take compound expressions, not just single
identifiers. The following is a shorter version of the preceding
proof:
#+BEGIN_SRC lean
-- BEGIN
theorem test (p q : Prop) (hp : p) (hq : q) : p ∧ q ∧ p :=
begin
  apply and.intro hp,
  exact and.intro hq hp
end
-- END
#+END_SRC
Unsurprisingly, it produces exactly the same proof term.
#+BEGIN_SRC lean
theorem test (p q : Prop) (hp : p) (hq : q) : p ∧ q ∧ p :=
begin
  apply and.intro hp,
  exact and.intro hq hp
end

-- BEGIN
print test
-- END
#+END_SRC

# TODO(Jeremy): will we eventually have a sequencing operator in Lean
# 3?

# Tactic applications can also be concatenated with a
# semicolon. Formally speaking, there is only one (compound) step in the
# following proof:
# #+BEGIN_SRC lean
# theorem test (p q : Prop) (hp : p) (hq : q) : p ∧ q ∧ p :=
# begin
#   apply (and.intro hp); exact (and.intro hq hp)
# end
# #+END_SRC

Whenever a proof term is expected, instead of using a =begin...end=
block, you can write the =by= keyword followed by a single tactic:
#+BEGIN_SRC lean
theorem test (p q : Prop) (hp : p) (hq : q) : p ∧ q ∧ p :=
by exact and.intro hp (and.intro hq hp)
#+END_SRC
In the Lean Emacs mode, if you put your cursor on the "b" in "by" and
press "C-c C-g", Lean shows you the goal that the tactic is supposed
to meet.

We will see below that hypothesis and be introduced, reverted,
modified, and renamed over the course of a tactic block. As a result,
it is impossible for the Lean parser to detect when an identifier that
occurs in a tactic block refers to a section variable that should
therefore be added to the context. As a result, you need to explicitly
tell Lean to include the relevant entities:
#+BEGIN_SRC lean
variables {p q : Prop} (hp : p) (hq : q)

include hp hq

example : p ∧ q ∧ p :=
begin
  apply and.intro hp,
  exact and.intro hq hp
end
#+END_SRC
The =include= command tells Lean to include the indicated variables
(as well as any variables they depend on) from that point on, until
the end of the section or file. The limit the effect of an =include=,
you can use the =omit= command afterwards:
#+BEGIN_SRC lean
variables {p q : Prop} (hp : p) (hq : q)

-- BEGIN
include hp hq

example : p ∧ q ∧ p :=
begin
  apply and.intro hp,
  exact and.intro hq hp
end

omit hp hq

-- hp and hq are no longer included by default
-- END
#+END_SRC
Alternatively, you can use a section to delimit the scope.
#+BEGIN_SRC lean
variables {p q : Prop} (hp : p) (hq : q)

-- BEGIN
section
include hp hq

example : p ∧ q ∧ p :=
begin
  apply and.intro hp,
  exact and.intro hq hp
end
end

-- hp and hq are no longer included by default
-- END
#+END_SRC
Another workaround is to find a way to
refer to the variable in question before entering a tactic block:
#+BEGIN_SRC lean
variables {p q : Prop} (hp : p) (hq : q)

-- BEGIN
example : p ∧ q ∧ p :=
let hp := hp, hq := hq in
begin
  apply and.intro hp,
  exact and.intro hq hp
end
-- END
#+END_SRC
Any mention of =hp= or =hq= at all will cause it to be added to the
hypotheses in the example.


** Basic Tactics

In addition to =apply= and =exact=, another useful tactic is =intro=,
which introduces a hypothesis. What follows is an example of an
identity from propositional logic that we proved [[file:03_Propositions_and_Proofs.org::#Examples_of_Propositional_Validities][Section 3.5]], now
proved using tactics. We adopt the following convention regarding
indentation: whenever a tactic introduces one or more additional
subgoals, we indent another two spaces, until the additional subgoals
are deleted. That rationale behind this convention, and other
structuring mechanisms, will be discussed in [[#Structuring_Tactic_Proofs][Section 5.4]] below.

#+BEGIN_SRC lean
example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) :=
begin
  apply iff.intro,
    intro h,
    apply or.elim (and.elim_right h),
      intro hq,
      apply or.intro_left,
      apply and.intro,
        exact and.elim_left h,
      exact hq,
    intro hr,
    apply or.intro_right,
    apply and.intro,
    exact and.elim_left h,
    exact hr,
  intro h,
  apply or.elim h,
    intro hpq,
    apply and.intro,
      exact and.elim_left hpq,
    apply or.intro_left,
    exact and.elim_right hpq,
  intro hpr,
  apply and.intro,
    exact and.elim_left hpr,
  apply or.intro_right,
  exact and.elim_right hpr
end
#+END_SRC

The =intro= command can more generally be used to introduce a variable
of any type:
#+BEGIN_SRC lean
example (α : Type) : α → α :=
begin
  intro a,
  exact a
end

example (α : Type) : ∀ x : α, x = x :=
begin
  intro x,
  exact eq.refl x
end
#+END_SRC
It has a plural form, =intros=, which takes a list of names.
#+BEGIN_SRC lean
example : ∀ a b c : ℕ, a = b → a = c → c = b :=
begin
  intros a b c h₁ h₂,
  exact eq.trans (eq.symm h₂) h₁
end
#+END_SRC
The =intros= command can also be used without any arguments, in which
case, it chooses names and introduces as many variables as it can. We
will see an example of this in a moment.

The =assumption= tactic looks through the assumptions in context of the
current goal, and if there is one matching the conclusion, it applies
it.
#+BEGIN_SRC lean
variables x y z w : ℕ

-- BEGIN
example (h₁ : x = y) (h₂ : y = z) (h₃ : z = w) : x = w :=
begin
  apply eq.trans h₁,
  apply eq.trans h₂,
  assumption   -- applied h₃
end
-- END
#+END_SRC
It will unify metavariables in the conclusion if necessary:
#+BEGIN_SRC lean
variables x y z w : ℕ

-- BEGIN
example (h₁ : x = y) (h₂ : y = z) (h₃ : z = w) : x = w :=
begin
  apply eq.trans,
  assumption,     -- solves x = ?m_1 with h₁
  apply eq.trans,
  assumption,     -- solves y = ?m_1 with h₂
  assumption      -- solves z = w with h₃
end
-- END
#+END_SRC
The following example uses the =intros= command to introduce the three
variables and two hypotheses automatically:
#+BEGIN_SRC lean
example : ∀ a b c : ℕ, a = b → a = c → c = b :=
begin
  intros,
  apply eq.trans,
  apply eq.symm,
  assumption,
  assumption
end
#+END_SRC

There are tactics =reflexivity=, =symmetry=, and =transitivity=, which
apply the corresponding operation. Using reflexivity, for example, is
more general than writing =apply eq.refl=, because it works for any
relation that has been tagged with the =refl= attribute.
# TODO: add a reference to the chapter that describes attributes.
With that tactic, the previous proof can be written more elegantly as
follows:
#+BEGIN_SRC lean
example : ∀ a b c : ℕ, a = b → a = c → c = b :=
begin
  intros,
  transitivity,
  symmetry,
  assumption,
  assumption
end
#+END_SRC

The =repeat= combinator can be used to simplify the last two lines:
#+BEGIN_SRC lean
example : ∀ a b c : ℕ, a = b → a = c → c = b :=
begin
  intros,
  apply eq.trans,
  apply eq.symm,
  repeat { assumption }
end
#+END_SRC
The curly braces introduce a new tactic block; they are equivalent to
a using a nested =begin ... end= pair, as discussed in the next section.

There is variant of =apply= called =fapply= that is more aggressive in
creating new subgoals for arguments. Here is an example of how it is
used:
#+BEGIN_SRC lean
example : ∃ a : ℕ, a = a :=
begin
  fapply exists.intro,
  exact 0,
  apply rfl
end
#+END_SRC
Here, the command =fapply exists.intro= creates two goals. The first
is to provide a natural number, =a=, and the second is to prove that
=a = a=. Notice that the second goal depends on the first; solving the
first goal instantiates a metavariable in the second.

Another tactic that is sometimes useful is the =generalize= tactic,
which is, in a sense, an inverse to =intro=.
#+BEGIN_SRC lean
variables x y z : ℕ

example : x = x :=
begin
  generalize x z, -- goal is x : ℕ ⊢ ∀ (z : ℕ), z = z
  intro y,      -- goal is x y : ℕ ⊢ y = y
  reflexivity
end
#+END_SRC
Te =generalize= tactic generalizes the conclusion over the variable
=x=, using a universal quantifier over =z=.  We can generalize any
term, not just a variable:
#+BEGIN_SRC lean
variables x y z : ℕ

-- BEGIN
example : x + y + z = x + y + z :=
begin
  generalize (x + y + z) w, -- goal is x y z : ℕ ⊢ ∀ (w : ℕ), w = w
  intro u,                  -- goal is x y z u : ℕ ⊢ u = u
  reflexivity
end
-- END
#+END_SRC
If the expression passed as the first argument to =generalize= is not
found in the goal, =generalize= raises an error.

Notice that once we generalize over =x + y + z=, the variables =x y
z : ℕ= in the context become irrelevant. The =clear= tactic throws
away elements of the context, when it is safe to do so:
#+BEGIN_SRC lean
variables x y z : ℕ

-- BEGIN
example : x + y + z = x + y + z :=
begin
  generalize (x + y + z) w, -- goal is x y z : ℕ ⊢ ∀ (w : ℕ), w = w
  clear x y z,
  intro u,                  -- goal is u : ℕ ⊢ u = u
  reflexivity
end
-- END
#+END_SRC

Another useful tactic is the =revert= tactic, which moves an element
of the context into the goal. When applied to a variable that occurs
in the goal, it has the
same effect as =generalize= and =clear=:
#+BEGIN_SRC lean
example (x : ℕ) : x = x :=
begin
  revert x,     -- goal is ⊢ ∀ (x : ℕ), x = x
  intro y,      -- goal is y : ℕ ⊢ y = y
  reflexivity
end
#+END_SRC
Moving a hypothesis into the goal yields an implication:
#+BEGIN_SRC lean
example (x y : ℕ) (h : x = y) : y = x :=
begin
  revert h,     -- goal is x y : ℕ ⊢ x = y → y = x
  intro h₁,     -- goal is x y : ℕ, h₁ : x = y ⊢ y = x
  symmetry,
  assumption
end
#+END_SRC
But =revert= is even more clever, in that it will revert not only an
element of the context but also all the subsequent elements of the
context that depend on it. For example, reverting =x= in the example
above brings =h= along with it:
#+BEGIN_SRC lean
example (x y : ℕ) (h : x = y) : y = x :=
begin
  revert x,     -- goal is y : ℕ ⊢ ∀ (x : ℕ), x = y → y = x
  intros,
  symmetry,
  assumption
end
#+END_SRC
You can also revert multiple elements of the context at once:
#+BEGIN_SRC lean
example (x y : ℕ) (h : x = y) : y = x :=
begin
  revert x y,     -- goal is ⊢ ∀ (x y : ℕ), x = y → y = x
  intros,
  symmetry,
  assumption
end
#+END_SRC

** More tactics

Some additional tactics are useful for constructing and destructing
propositions and data. For example, when applied to a goal of the form
=p ∨ q=, the tactics =left= and =right= are equivalent =apply or.inl=
and apply =or.inr=, respectively.  Conversely, the =cases= tactic can
be used to decompose a disjunction.
#+BEGIN_SRC lean
example (p q : Prop) : p ∨ q → q ∨ p :=
begin
  intro h,
  cases h with hp hq,
  -- case hp : p
  right, exact hp,
  -- case hq : q
  left, exact hq 
end
#+END_SRC
After =cases h= is applied, there are two goals. In the first, the
hypothesis =h : p ∨ q= is replaced by =hp : p=, and in the second, it
is replaced by =hq : q=.  The =cases= can also be used to decompose
a conjunction.
#+BEGIN_SRC lean
example (p q : Prop) : p ∧ q → q ∧ p :=
begin
  intro h,
  cases h with hp hq,
  constructor, exact hq, exact hp
end
#+END_SRC
In this case, there is only one goal after the =cases= tactic is
applied, with =h : p ∧ q= replaced by a pair of assumptions, =hp : p=
and =hq : q=. The constructor applies the unique constructor for
conjunction, =and.intro=. With these tactics, an example from the
previous section can be rewritten as follows:
#+BEGIN_SRC lean
example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) :=
begin
  apply iff.intro,
  intro h,
   cases h with hp hqr,
   cases hqr with hq hr,
     left, constructor, repeat { assumption },
     right, constructor, repeat { assumption },
  intro h,
    cases h with hpq hpr,
      cases hpq with hp hq, 
        constructor, exact hp, left, exact hq,
      cases hpr with hp hr,
        constructor, exact hp, right, exact hr
end
#+END_SRC

We will see in [[file:07_Inductive_Types.org::#Inductive_Types][Chapter 7]] that these tactics are quite general. The
=cases= tactic can be used to decompose any element of an inductively
defined type; =constructor= always applies the first constructor of an
inductively type, and =left= and =right= can be used with inductively
defined types with exactly =two= constructors. For example, we can
uses =cases= and =constructor= with an existential quantifier:
#+BEGIN_SRC lean
example (p q : ℕ → Prop) : (∃ x, p x) → ∃ x, p x ∨ q x :=
begin
  intro h,
  cases h with x px,
  constructor, left, exact px 
end
#+END_SRC
Here, the =constructor= tactic leaves the first component of the
existential assertion, the value of =x=, implicit. It is represented
by a metavariable, which should be instantiated later on. In the
previous example, the proper value of the metavariable is determine by
the tactic =exact px=, since =px= has type =p x=. If you want to
specify a witness to the existential quantifier explicitly, you can
use the =existsi= tactic instead:
#+BEGIN_SRC lean
example (p q : ℕ → Prop) : (∃ x, p x) → ∃ x, p x ∨ q x :=
begin
  intro h,
  cases h with x px,
  existsi x, left, exact px 
end
#+END_SRC

These tactics can be used on data just as well as propositions. In the
next two example, they are used to define functions which swap the
components of the product and sum types:
#+BEGIN_SRC lean
universe variables u v

def swap_pair {α : Type u} {β : Type v} : α × β → β × α :=
begin
  intro p,
  cases p with ha hb,
  constructor, exact hb, exact ha
end

def swap_sum {α : Type u} {β : Type v} : α ⊕ β → β ⊕ α :=
begin
  intro p,
  cases p with ha hb,
    right, exact ha,
    left, exact hb
end
#+END_SRC
Note that up to the names we have chosen for the variables, the
definitions are identical to the proofs of the analogous propositions
for conjunction and disjunction. The =cases= tactic will also do a
case distinction on a natural number:
#+BEGIN_SRC lean
open nat

example (P : ℕ → Prop) (h₀ : P 0) (h₁ : ∀ n, P (succ n)) (m : ℕ) : P m :=
begin
  cases m with m', exact h₀, exact h₁ m'
end
#+END_SRC
For further discussion, see [[file:07_Inductive_Types.org::#Inductive_Types][Chapter 7]].

# TODO: here and above, add a more specific section reference.

** Structuring Tactic Proofs
:PROPERTIES:
  :CUSTOM_ID: Structuring_Tactic_Proofs
:END:

Tactics often provide an efficient way of building a proof, but long
sequences of instructions can obscure the structure of the
argument. In this section, we describe some means that help provide
structure to a tactic-style proof, making such proofs more readable
and robust.

One thing that is nice about Lean's proof-writing syntax is that it is
possible to mix term-style and tactic-style proofs, and pass
between the two freely. For example, the tactics =apply= and =exact=
expect arbitrary terms, which you can write using =have=, =show=,
and so on. Conversely, when writing an arbitrary Lean term,
you can always invoke the tactic mode by inserting a =begin...end=
block. The following is a somewhat toy example:
#+BEGIN_SRC lean
example (p q r : Prop) : p ∧ (q ∨ r) → (p ∧ q) ∨ (p ∧ r) :=
begin
  intro h,
  exact
    have hp : p, from h^.left,
    have hqr : q ∨ r, from h^.right,
    show (p ∧ q) ∨ (p ∧ r),
    begin
      cases hqr with hq hr,
        exact or.inl ⟨hp, hq⟩,
      exact or.inr ⟨hp, hr⟩
    end
end
#+END_SRC
The following is a more natural example:
#+BEGIN_SRC lean
example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) :=
begin
  apply iff.intro,
    intro h,
    cases h^.right with hq hr,
      exact 
        show (p ∧ q) ∨ (p ∧ r), 
          from or.inl ⟨h^.left, hq⟩,
    exact 
      show (p ∧ q) ∨ (p ∧ r), 
        from or.inr ⟨h^.left, hr⟩,
  intro h,
  cases h with hpq hpr,
    exact 
      show p ∧ (q ∨ r), 
        from ⟨hpq^.left, or.inl hpq^.right⟩,
  exact show p ∧ (q ∨ r), 
    from ⟨hpr^.left, or.inr hpr^.right⟩
end
#+END_SRC
With the =exact= tactic, we use =show= to indicate the goal at that
point in the proof. In fact, this idiom is so useful that Lean offers
the following abbreviation: in a tactic block, the expression =show p,
from t= abbreviates =exact (show p, from t)=. Thus we could have
written the previous example more concisely as follows:
#+BEGIN_SRC lean
example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) :=
begin
  apply iff.intro,
    intro h,
    cases h^.right with hq hr,
      show (p ∧ q) ∨ (p ∧ r),
        from or.inl ⟨h^.left, hq⟩,
    show (p ∧ q) ∨ (p ∧ r),
      from or.inr ⟨h^.left, hr⟩,
  intro h,
  cases h with hpq hpr,
    show p ∧ (q ∨ r), 
      from ⟨hpq^.left, or.inl hpq^.right⟩,
  show p ∧ (q ∨ r), 
    from ⟨hpr^.left, or.inr hpr^.right⟩
end
#+END_SRC
This blurs the distinction between proof-term mode and tactic-mode,
and so it is important to use indentation and the structuring
mechanisms discussed below to make it clear where a proof term ends.
The convention we have used for indentation will be explained momentarily.

In the same way, in a tactic block, Lean interprets =have p, from t₁,
t₂= as as an abbreviation for =exact (have p, from t₁, t₂)=. Thus the
first example in this section could have been written more concisely
as follows:
#+BEGIN_SRC lean
example (p q r : Prop) : p ∧ (q ∨ r) → (p ∧ q) ∨ (p ∧ r) :=
begin
  intro h,
  have hp : p, from h^.left,
  have hqr : q ∨ r, from h^.right,
  show (p ∧ q) ∨ (p ∧ r),
  begin
    cases hqr with hq hr,
      exact or.inl ⟨hp, hq⟩,
    exact or.inr ⟨hp, hr⟩
  end
end
#+END_SRC

You can also nest =begin...end= blocks within other =begin...end=
blocks.  In a nested block, Lean focuses on the first goal, and
generates an error if it has not been fully solved at the end of the
block.  This can be helpful in indicating the separate proofs of
multiple subgoals introduced by a tactic.
#+BEGIN_SRC lean
example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) :=
begin
  apply iff.intro,
  begin
    intro h,
    cases h^.right with hq hr,
    begin
      show (p ∧ q) ∨ (p ∧ r),
        from or.inl ⟨h^.left, hq⟩
    end,
    show (p ∧ q) ∨ (p ∧ r),
      from or.inr ⟨h^.left, hr⟩
  end,
  intro h,
  cases h with hpq hpr,
  begin
    show p ∧ (q ∨ r), from
      ⟨hpq^.left, or.inl hpq^.right⟩
  end,
  show p ∧ (q ∨ r), from
    ⟨hpr^.left, or.inr hpr^.right⟩
end
#+END_SRC
Here, we have introduced a new =begin..end= block whenever a tactic
leaves more than one subgoal. You can check (using =C-c C-g= in Emacs
mode, for example) that every line in this proof, there is only one
goal visible. Notice that you still need to use a comma after a
=begin...end= block when there are remaining goals to be
discharged. 

Within a =begin...end= block, you can abbreviate nested occurrences of
=begin= and =end= with curly braces:
#+BEGIN_SRC lean
example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) :=
begin
  apply iff.intro,
  { intro h,
    cases h^.right with hq hr,
    { show (p ∧ q) ∨ (p ∧ r),
        from or.inl ⟨h^.left, hq⟩ },
    show (p ∧ q) ∨ (p ∧ r),
      from or.inr ⟨h^.left, hr⟩ },
  intro h,
  cases h with hpq hpr,
  { show p ∧ (q ∨ r),
      from ⟨hpq^.left, or.inl hpq^.right⟩ },
  show p ∧ (q ∨ r),
    from ⟨hpr^.left, or.inr hpr^.right⟩
end
#+END_SRC
This helps explain the convention on indentation we have adopted here:
every time a tactic leaves more than one subgoal, we separate the
remaining subgoals by enclosing them in blocks and indenting, until we
are back down to one subgoal. Thus if the application of theorem =foo=
to a single goal produces four subgoals, one would expect the proof to
look like this:
#+BEGIN_SRC lean_text
begin
  apply foo,
  { ... proof of first goal ... },
  { ... proof of second goal ... },
  { ... proof of third goal ... },
  proof of final goal
end
#+END_SRC

Another reasonable convention is to enclose /all/ the remaining subgoals
in indented blocks, including the last one:
#+BEGIN_SRC lean
example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) :=
begin
  apply iff.intro,
  { intro h,
    cases h^.right with hq hr,
    { show (p ∧ q) ∨ (p ∧ r),
        from or.inl ⟨h^.left, hq⟩ },
    { show (p ∧ q) ∨ (p ∧ r),
        from or.inr ⟨h^.left, hr⟩ }},
  { intro h,
    cases h with hpq hpr,
    { show p ∧ (q ∨ r),
        from ⟨hpq^.left, or.inl hpq^.right⟩ },
    { show p ∧ (q ∨ r),
        from ⟨hpr^.left, or.inr hpr^.right⟩ }}
end
#+END_SRC
With this convention, the proof using =foo= described above would look
like this:
#+BEGIN_SRC lean_text
begin
  apply foo,
  { ... proof of first goal ... },
  { ... proof of second goal ... },
  { ... proof of third goal ... },
  { ... proof of final goal ....}
end
#+END_SRC

Both conventions are reasonable. The second convention has the effect
that the text in a long proof gradually creeps to the right. Many
theorems in mathematics have side conditions that can be dispelled
quickly; using the first convention means that the proofs of these
side conditions are indented until we return to the "linear" part of
the proof.

You can simulate the effect of the =have= construct without leaving
tactic mode using the =assert= tactic.
#+BEGIN_SRC lean
example (p q : Prop) : p ∧ q ↔ q ∧ p :=
begin
  apply iff.intro,
  { intro h,
    assert hp : p, exact h^.left,
    assert hq : q, exact h^.right,
    exact ⟨hq, hp⟩ },
  intro h,
  assert hp : p, exact h^.right,
  assert hq : q, exact h^.left,
  exact ⟨hp, hq⟩
end
#+END_SRC
Here, the first =assert= creates a new subgoal, =p=. After that
subgoal is proved, we are left with the original subgoal, with the
context augmented by =hp : p=. Tactics are used are to prove both
subgoals.

Another option is to use the =note= tactic, which allows you to insert
a fact into the context, without having to state the proposition it
proves.
#+BEGIN_SRC lean
example (p q : Prop) : p ∧ q ↔ q ∧ p :=
begin
  apply iff.intro,
  { intro h,
    note hp := h^.left,
    note hq := h^.right,
    exact ⟨hq, hp⟩ },
  intro h,
  note hp := h^.right,
  note hq := h^.left,
  exact ⟨hp, hq⟩
end
#+END_SRC
In general, if =e= has type =t=, then ~note h := e~ adds a hypothesis
=h : t= to the context, without giving you access to the contents of
=e=. If, instead, you need the contents of =e=, use ~pose x := e~
instead. This adds ~x : t := e~ to the context as a =let= definition
that can be unfolded when needed. Here is an example:
#+BEGIN_SRC lean
example : ∃ x : ℕ, x + 3 = 8 :=
begin
  pose x := 5,
  existsi x,
  reflexivity
end
#+END_SRC

Just as the =assert= tactic can be used to simulate the benefits of
=have=, the =change= tactic can be used to simulate the benefits of
=show=. In the following example, the tactic =change q= affirms that the
goal at that point is =q=, and the tactic =change p= affirms that the
goal is =p=.
#+BEGIN_SRC lean
example (p q : Prop) : p ∧ q → q ∧ p :=
begin
  intro h,
  split,
  { change q,
    exact h^.right },
  change p,
  exact h^.left
end
#+END_SRC
The name of the =change= tactic is explained by the fact that it can
be used to replace a goal by any definitionally equivalent statement.
#+BEGIN_SRC lean
example (a b : ℕ) (h : a = b) : a + 0 = b + 0 :=
begin
  change a = b,
  assumption
end
#+END_SRC
The =change= statement will also work if the expression you give it
has metavariables, in which case, it tries to unify the expression
with the goal.
#+BEGIN_SRC lean
example (a b c : ℕ) (h₁ : a = b) (h₂ : b = c) : a = c :=
begin
  transitivity,
    change _ = b, assumption,
  assumption
end
#+END_SRC
In this example, after the =transitivity= tactic is applied, there are
two goals, =a = ?m_1= and =?m_1 = c=. After the =change=, the two
goals have been specialized to =a = b= and =b = c=. 

# TODO(Jeremy): also describe
#   tactic combinators (like =try=)
#   tactics that manage goals
#   subst, contradiction, refine

# TODO(Jeremy): break into two sections when this gets long enough

** Rewriting and the Simplifier

The =rewrite= tactic (abbreviated =rw=) and the =simp= tactic were
introduced in [[file:04_Quantifiers_and_Equality.org::#Calculational_Proofs][Section 4.3]]. In this section, we discuss them in greater detail.

The =rewrite= tactic provide a basic mechanism for applying
substitutions to goals and hypotheses, providing a convenient and
efficient way of working with equality. The most basic form of the
tactic is =rewrite t=, where =t= is a term which conclusion is an
equality. In the following example, we use this basic form to rewrite
the goal using a hypothesis.
#+BEGIN_SRC lean
variables (f : ℕ → ℕ) (k : ℕ)

example (h₁ : f 0 = 0) (h₂ : k = 0) : f k = 0 :=
begin
  rw h₂, -- replace k with 0
  rw h₁  -- replace f 0 with 0
end
#+END_SRC
In the example above, the first use of =rw= replaces =k= with =0= in
the goal =f k = 0=.  Then, the second one replaces =f 0= with =0=. The
tactic automatically closes any goal of the form =t = t=.

Multiple rewrites can be combined using the notation =rw [t_1,
..., t_n]=, which is just shorthand for =rewrite t_1, ..., rewrite
t_n=.  The previous example can be written as follows:
#+BEGIN_SRC lean
variables (f : ℕ → ℕ) (k : ℕ)

example (h₁ : f 0 = 0) (h₂ : k = 0) : f k = 0 :=
begin
  rw [h₂, h₁]
end
#+END_SRC

By default, =rw= uses an equation in the forward direction, matching
the left-hand side with an expression, and replacing it with the
right-hand side. The notation =-t= can be used to instruct the tactic
to use the equality =t= in the reverse direction.
#+BEGIN_SRC lean
variables (f : ℕ → ℕ) (a b : ℕ)

example (h₁ : a = b) (h₂ : f a = 0) : f b = 0 :=
begin
  rw [-h₁, h₂]
end
#+END_SRC
In this example, the term =-h₁= instructs the rewriter to replace
=b= with =a=.

Sometimes the left-hand side of an identity can match more than one
subterm in the pattern, in which case the =rewrite= tactic chooses
the first match it finds when traversing the term. If that is not the
one you want, you can use additional arguments to specify the
appropriate subterm.
#+BEGIN_SRC lean
example (a b c : ℕ) : a + b + c = a + c + b :=
begin
  rw [add_assoc, add_comm b, -add_assoc]
end

example (a b c : ℕ) : a + b + c = a + c + b :=
begin
  rw [add_assoc, add_assoc, add_comm b]
end

example (a b c : ℕ) : a + b + c = a + c + b :=
begin
  rw [add_assoc, add_assoc, add_comm _ b]
end
#+END_SRC
In the first example above, the first step rewrites =a + b + c= to
=a + (b + c)=.  Then next applies commutativity to the term =b + c=;
without specifying the argument, the tactic would instead rewrite =a +
(b + c)= to =(b + c) + a=.  Finally, the last step applies
associativity in the reverse direction rewriting =a + (c + b)= to =a +
c + b=. The next two examples instead apply associativity to move the
parenthesis to the right on both sides, and then switch =b= and
=c=. Notice that the last example specifies that the rewrite should
take place on the right-hand side by specifying the second argument to
=add_comm=. 

By default, the =rewrite= tactic affects only the goal. The notation
=rw t at h= applies the rewrite =t= at hypothesis =h=.
#+BEGIN_SRC lean
variables (f : ℕ → ℕ) (a : ℕ)

example (h : a + 0 = 0) : f a = f 0 :=
begin
  rw add_zero at h, rw h
end
#+END_SRC
The first step, =rw add_zero at h=, rewrites the hypothesis =a + 0 = 0=
to =a = 0=. Then the new hypothesis =a = 0= is used to rewrite the
goal to =f 0 = f 0=.

# TODO(Jeremy): in this next example, eliminate the definition of
# tuple when it is in the library.

The =rewrite= tactic is not restricted to propositions. In the
following example, we use =rw h at t= to rewrite the hypothesis
=t : tuple α n= to =v : tuple α 0=.
#+BEGIN_SRC lean
universe variable u

definition tuple (α : Type u) (n : ℕ) := { l : list α // list.length l = n }

variables {α : Type u} {n : ℕ}

example (h : n = 0) (t : tuple α n) : tuple α 0 :=
begin
  rw h at t,
  exact t
end
#+END_SRC

Note that the rewrite tactic can carry out generic calculuations in
any algebraic structure. The following examples involve an arbitrary
ring and an arbitrary group, respectively.
#+BEGIN_SRC lean
universe variable uu

example {α : Type uu} [ring α] (a b c : α) : a * 0 + 0 * b + c * 0 + 0 * a = 0 :=
begin
  rw [mul_zero, mul_zero, zero_mul, zero_mul],
  repeat { rw add_zero }
end

example {α : Type uu} [group α] {a b : α} (h : a * b = 1) : a⁻¹ = b :=
by rw [-(mul_one a⁻¹), -h, inv_mul_cancel_left]
#+END_SRC
Using the type class mechanism described in [[file:10_Type_Classes.org::#Type_Classes][Chapter 10]], Lean
identifies both abstract and concrete instances of the relevant
algebraic structures, and instantiates the relevant facts accordingly.

# TODO(Jeremy): add a reference to the chapter on attributes

Whereas =rewrite= is designed as a surgical tool for manipulating a
goal, the simplifier offers a powerful form of automation. A number of
identities in Lean's library have been tagged with the =[simp]=
attribute, and the =simp= tactic uses them to iteratively rewrite
subterms in an expression. 
#+BEGIN_SRC lean
variables (x y z : ℕ) (p : ℕ → Prop)
premise   (h : p (x * y))

example : (x + 0) * (0 + y * 1 + z * 0) = x * y :=
by simp

include h
example : p ((x + 0) * (0 + y * 1 + z * 0)) :=
begin simp, assumption end
#+END_SRC
In the first example, the left-hand side of the equality in the goal
is simplifier using the usual identities involving 0 and 1, reducing
the goal to =x * y = x * y=. At that point, =simp= applies reflexivity
to finish it off. In the second example, =simp= reduces the goal to =p
(x * y)=, at which point the assumption =h= finishes it off.

As with =rw=, you can use the keyword =at= to simplify a hypothesis:
#+BEGIN_SRC lean
variables (x y z : ℕ) (p : ℕ → Prop)

-- BEGIN
example (h : p ((x + 0) * (0 + y * 1 + z * 0))) : p (x * y) :=
begin simp at h, assumption end
-- END
#+END_SRC

For operations that are commutative and associative, like addition on
the natural numbers, the simplifier uses these two facts to rewrite an
expression, as well as /left commutativity/. In the case of additition
the latter is expressed as follows: =x + (y + z) = y + (x + z)=. It
may seem that commutativity and left-commutativity are problematic, in
that repeated application of either causes looping. But the simplifier
detects identities that permute their arguments, and uses a technique
known as /ordered rewriting/. This means that that the system
maintains an internal ordering of terms, and only applies the identity
if doing so decreases the order. With the three identities mentioned
above, this has the effect that all the parentheses in an expression
are associated to the right, and the expressions are ordered in a
canonical (though somewhat arbitrary) way. Two expressions that are
equivalent up to associativity and commutativity are then rewritten to
the same canonical form.
#+BEGIN_SRC lean
variables (x y z w : ℕ) (p : ℕ → Prop)

example : x * y + z * w  * x = x * w * z + y * x :=
by simp

example (h : p (x * y + z * w  * x)) : p (x * w * z + y * x) :=
begin simp, simp at h, assumption end
#+END_SRC
As with the rewriter, the simplifier behaves appropriately in
algebraic structures:
#+BEGIN_SRC lean
variables {α : Type} [comm_ring α]
 
example (x y z : α) : (x - x) * y + z = z :=
begin simp end

example (x y z w : α) : x * y + z * w  * x = x * w * z + y * x :=
by simp
#+END_SRC

Also as with the =rewrite= tactic, you can pass additional arguments
to =simp=. These can either be names of theorems or expressions.
The =simp= tactic does not recognize the =-t= syntax, so to use an
identity in the other direction you need to use =eq.symm=
explicitly. In any case, the additional rules are added to the
collection of identities that are used to simplify a term.
#+BEGIN_SRC lean
def f (m n : ℕ) : ℕ := m + n + m

theorem f.def (m n : ℕ) : f m n = m + n + m := rfl

example {m n : ℕ} (h : n = 1) (h' : 0 = m) : (f m n) * m = m :=
by simp [h, h'^.symm, f.def]
#+END_SRC
If we add the attribute =[simp]= to the theorem =f.def=, we do not
need to include it.
#+BEGIN_SRC lean
def f (m n : ℕ) : ℕ := m + n + m

@[simp]
theorem f.def (m n : ℕ) : f m n = m + n + m := rfl

example {m n : ℕ} (h : n = 1) (h' : 0 = m) : (f m n) * m = m :=
by simp [h, h'^.symm]
#+END_SRC

# TODO(Jeremy): still need to:
#   Describe more features of the simplifier (as they become
#     available)
#   Talk about conditional rewriting
#   Use more impressive examples
#   Show a calculation with numerals
#   Indicate that there is a configurable version (that will be
#     discussed in /Programming in Lean/?).
#
#   Describe drewrite and dsimp
#   Describe erewrite
#   Describe unfold
#   In the chapter on function definitions, write about using
#     the generated equations.
#   Use the simplifier in inductive proofs later on

# TODO(Jeremy): This is old text, describing the rewrite tactic in
# Lean 2.

# The notation =*t= instructs the rewriter to apply the rewrite =t= zero
# or more times, while the notation =+t= instructs the rewriter to use
# it at least once. Note that rewriting with =*t= never fails.
# #+BEGIN_SRC lean
# import data.nat
# open nat algebra

# example (x y : ℕ) : (x + y) * (x + y) = x * x + y * x + x * y + y * y :=
# by rewrite [*left_distrib, *right_distrib, -add.assoc]
# #+END_SRC

# To avoid non-termination, the =rewriter= tactic has a limit on the
# maximum number of iterations performed by rewriting steps of the form
# =*t= and =+t=. For example, without this limit, the tactic =rewrite
# *add.comm= would make Lean diverge on any goal that contains a
# sub-term of the form =t + s= since commutativity would be always
# applicable. The limit can be modified by setting the option
# =rewriter.max_iter=.

# The notation =rewrite n t=, where =n=, is a positive number indicates
# that =t= must be applied exactly =n= times. Similarly, =rewrite n>t=
# is notation for at most =n= times.

# A pattern =p= can be optionally provided to a rewriting step =t= using
# the notation ={p}t= .  It allows us to specify where the rewrite
# should be applied. This feature is particularly useful for rewrite
# rules such as commutativity =a + b = b + a= which may be applied to
# many different sub-terms. A pattern may contain placeholders. In the
# following example, the pattern =b + _= instructs the =rewrite= tactic
# to apply commutativity to the first term that matches =b + _=, where
# =_= can be matched with an arbitrary term.
# #+BEGIN_SRC lean
# import data.nat
# open nat algebra
# -- BEGIN
# example (a b c : ℕ) : a + b + c = a + c + b :=
# begin
#   rewrite [add.assoc, {b + _}add.comm, -add.assoc]
# end
# -- END
# #+END_SRC
# In the example above, the first step rewrites =a + b + c= to =a + (b +
# c)=.  Then, ={b + _}add.comm= applies commutativity to the term =b +
# c=. Without the pattern ={b + _}=, the tactic would instead rewrite
# =a + (b + c)= to =(b + c) + a=.  Finally, =-add.assoc= applies
# associativity in the "reverse direction" rewriting =a + (c + b)= to
# =a + c + b=.

# Multiple hypotheses can be specified in the same =at= clause.
# #+BEGIN_SRC lean
# import data.nat
# open nat algebra
# -- BEGIN
# variables (a b : ℕ)

# example (h₁ : a + 0 = 0) (h₂ : b + 0 = 0) : a + b = 0 :=
# begin
#   rewrite add_zero at (h₁, h₂),
#   rewrite [h₁, h₂]
# end
# -- END
# #+END_SRC

# You may also use =t at *= to indicate that all hypotheses and the goal should
# be rewritten using =t=. The tactic step fails if none of them can be rewritten.
# The notation =t at * ⊢= applies =t= to all hypotheses. You can enter
# the symbol =⊢= by typing =\|-=.
# #+BEGIN_SRC lean
# import data.nat
# open nat algebra
# -- BEGIN
# variables (a b : ℕ)

# example (h₁ : a + 0 = 0) (h₂ : b + 0 = 0) : a + b + 0 = 0 :=
# begin
#   rewrite add_zero at *,
#   rewrite [h₁, h₂]
# end
# -- END
# #+END_SRC
# The step =add_zero at *= rewrites the hypotheses =h₁=, =h₂= and the main goal
# using the =add_zero (x : ℕ) : x + 0 = x=, producing =a = 0=, =b = 0= and
# =a + b = 0= respectively.

# Given a rewrite =(t : l = r)=, the tactic =rewrite t= by default
# locates a sub-term =s= which matches the left-hand-side =l=, and then
# replaces all occurrences of =s= with the corresponding
# right-hand-side. The notation =at {i_1, ..., i_k}= can be used to
# restrict which occurrences of the sub-term =s= are replaced. For
# example, =rewrite t at {1, 3}= specifies that only the first and third
# occurrences should be replaced.
# #+BEGIN_SRC lean
# import data.nat
# open ℕ
# -- BEGIN
# variables (f : ℕ → ℕ → ℕ → ℕ) (a b : ℕ)

# example (h₁ : a = b) (h₂ : f b a b = 0) : f a a a = 0 :=
# by rewrite [h₁ at {1, 3}, h₂]
# -- END
# #+END_SRC
# Similarly, =rewrite t at h {1, 3}= specifies that =t= must be applied
# to hypothesis =h= and only the first and third occurrences must be
# replaced. You can also specify which occurrences should not be
# replaced using the notation =rewrite t at -{i_1, ..., i_k}=. Here is
# the previous example using this feature.
# #+BEGIN_SRC lean
# import data.nat
# open ℕ

# variables (f : ℕ → ℕ → ℕ → ℕ) (a b : ℕ)
# -- BEGIN
# example (h₁ : a = b) (h₂ : f b a b = 0) : f a a a = 0 :=
# by rewrite [h₁ at -{2}, h₂]
# -- END
# #+END_SRC

# The =rewrite= tactic also supports reduction steps: =↑f=, =▸*=, =↓t=,
# and =▸t=.  The step =↑f= unfolds =f= and performs beta/iota reduction
# and simplify projections.  This step fails if there is no =f= to be
# unfolded. The step =▸*= is similar to =↑f=, but does not take a
# constant to unfold as argument, therefore it never fails.  The fold
# step =↓t= unfolds the head symbol of =t=, then search for the result
# in the goal (or a given hypothesis), and replaces any match with
# =t=. Finally, =▸t= tries to reduce the goal (or a given hypothesis) to
# =t=, and fails if it is not convertible to =t=.  (The up arrow is
# entered with =\u=, the down arrow is entered with =\d=, and the right
# triangle is entered with =\t=. You can also use the ASCII alternatives
# =^f=, =>*=, =<d t=, and => t= for =↑f=, =▸*=, =↓t=, and =▸t=,
# respectively.)

# #+BEGIN_SRC lean
# import data.nat
# open nat
# -- BEGIN
# definition double (x : ℕ) := x + x

# variable f : ℕ → ℕ

# example (x y : ℕ) (h₁ : double x = 0) (h₃ : f 0 = 0) : f (x + x) = 0 :=
# by rewrite [↑double at h₁, h₁, h₃]
# -- END
# #+END_SRC
# The step =↑double at h₁= unfolds =double= in the hypothesis =h₁=.
# The notation =rewrite ↑[f_1, ..., f_n]= is shorthand for
# =rewrite [↑f_1, ..., ↑f_n]=

# The tactic =esimp= is a shorthand for =rewrite ▸*=. Here are two simple examples:
# #+BEGIN_SRC lean
# open sigma ℕ

# example (x y : ℕ) (h : (fun (a : ℕ), pr1 ⟨a, y⟩) x = 0) : x = 0 :=
# begin
#   esimp at h,
#   exact h
# end

# example (x y : ℕ) (h : x = 0) : (fun (a : ℕ), pr1 ⟨a, y⟩) x = 0 :=
# begin
#   esimp,
#   exact h
# end
# #+END_SRC
# Here is an example where the fold step is used to replace =a + 1= with =f a=
# in the main goal.
# #+BEGIN_SRC lean
# open nat

# definition foo [irreducible] (x : ℕ) := x + 1

# example (a b : ℕ) (h : foo a = b) : a + 1 = b :=
# begin
#   rewrite ↓foo a,
#   exact h
# end
# #+END_SRC

# Here is another example: given any type =α=, we show that the =list α=
# append operation =s ++ t= is associative.
# #+BEGIN_SRC lean
# import data.list
# open list
# variable {α : Type}

# theorem append_assoc : ∀ (s t u : list α), s ++ t ++ u = s ++ (t ++ u)
# | append_assoc nil t u      := by apply rfl
# | append_assoc (a :: l) t u :=
#   begin
#     rewrite ▸ a :: (l ++ t ++ u) = _,
#     rewrite append_assoc
#   end
# #+END_SRC
# We discharge the inductive cases using the =rewrite= tactic. The base
# case is solved by applying reflexivity, because =nil ++ t ++ u= and
# =nil ++ (t ++ u)= are definitionally equal. In the inductive step, we
# first reduce the goal =a :: s ++ t ++ u = a :: s ++ (t ++ u)= to =a ::
# (s ++ t ++ u) = a :: s ++ (t ++ u)= by applying the reduction step =▸
# a :: (l ++ t ++ u) = _=.  The idea is to expose the term =l ++ t ++
# u=, which can be rewritten using the inductive hypothesis
# =append_assoc (s t u : list α) : s ++ t ++ u = s ++ (t ++ u)=. Notice
# that we used a placeholder =_= in the right-hand-side of this
# reduction step; this placeholder is unified with the right-hand-side
# of the main goal. As a result, we do not have the copy the right-hand
# side of the goal.

# There are two variants of =rewrite=, namely =krewrite= and =xrewrite=,
# that are more aggressive about matching patterns. =krewrite= will
# unfold definitions as long as the head symbol matches, for example,
# when trying to match a pattern =f p= with an expression =f t=. In
# contrast, =xrewrite= will unfold all definitions that are not marked
# irreducible. Both are computationally expensive and should be used
# sparingly. =krewrite= is often useful when matching patterns requires
# unfolding projections in an algebraic structure.
